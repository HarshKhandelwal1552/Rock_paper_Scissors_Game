{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91946\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing required liberaries\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.externals import joblib\n",
    "from skimage.color import rgb2gray\n",
    "# importing lberaries for model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,MaxPooling2D,BatchNormalization,GlobalAveragePooling2D,Dropout,Flatten,GaussianNoise\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saver/mobilenetv2_complete_dataset.json','r') as json_file:\n",
    "\n",
    "    json_SavedModel = json_file.read()\n",
    "model = tf.keras.models.model_from_json(json_SavedModel)\n",
    "model.load_weights('saver/mobilenetv2_complete_dataset.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_96 (Model)  (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,422,339\n",
      "Trainable params: 2,388,227\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Gestures and converting them into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def decoding_gestures(class_p1,class_p2,score_p1,score_p2):\n",
    "    class_p1_copy = copy.copy(class_p1[:])\n",
    "    class_p1_copy = np.array(class_p1_copy).reshape(-1,3)\n",
    "    p1 = np.bincount(np.argmax(class_p1_copy,axis =1)).argmax()\n",
    "\n",
    "    class_p2_copy = copy.copy(class_p2[:])\n",
    "    class_p2_copy = np.array(class_p2_copy).reshape(-1,3)\n",
    "    p2 = np.bincount(np.argmax(class_p2_copy,axis =1)).argmax()\n",
    "    txt,score_p1,score_p2 = declearation(p1,p2,score_p1,score_p2)\n",
    "    \n",
    "    return txt,score_p1,score_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the game rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declearation(p1,p2,score_p1,score_p2):    \n",
    "    if p1==0 and p2 == 1:\n",
    "        txt = 'p1: Is decleared Winner'\n",
    "        score_p1 = score_p1 + 1\n",
    "\n",
    "    elif p1==1 and p2 == 0:\n",
    "        txt = 'p2: Is decleared Winner'\n",
    "        score_p2 = score_p2 + 1\n",
    "\n",
    "    elif p1==0 and p2 == 2:\n",
    "        txt = 'p2: Is decleared Winner'\n",
    "        score_p2 = score_p2 + 1\n",
    "\n",
    "    elif p1==2 and p2 == 0:\n",
    "        txt = 'p1: Is decleared Winner'    \n",
    "        score_p1 = score_p1 + 1\n",
    "\n",
    "    elif p1==1 and p2 == 2:\n",
    "        txt = 'p1: Is decleared Winner'\n",
    "        score_p1 = score_p1 + 1\n",
    "\n",
    "    elif p1==2 and p2 == 1:\n",
    "        txt = 'p2: Is decleared Winner' \n",
    "        score_p2 = score_p2 + 1\n",
    "\n",
    "    else :\n",
    "        txt = \"Its a draw\"\n",
    "        \n",
    "    return txt,score_p1,score_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the values to have track on the game  \n",
    "class_p1 = []\n",
    "class_p2 = []\n",
    "i = 0\n",
    "score_p1 = 0\n",
    "score_p2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the Game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its a draw\n",
      "p2: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "Its a draw\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "p2: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p2: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "Its a draw\n",
      "p1: Is decleared Winner\n",
      "p1: Is decleared Winner\n",
      "Its a draw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we use the ip webcam for using mobile camera for displaing on our pc \n",
    "while True:\n",
    "    \n",
    "    # getting the address for our mobile camera\n",
    "    \n",
    "    # here instead of 19x.xxx.xx.x:8080 you write your own ip given by ip webcam for your android\n",
    "    image = requests.get(\"http://19x.xxx.xx.x:8080/shot.jpg\") \n",
    "    \n",
    "    # conveerting into numpy array\n",
    "    video = np.array(bytearray(image.content),dtype = np.uint8)\n",
    "    \n",
    "    # decoding our numpy array\n",
    "    render = cv2.imdecode(video,-1)\n",
    "    #print(render.shape)\n",
    "    \n",
    "    # Reading an image in default mode \n",
    "   \n",
    "    # Window name in which image is displayed \n",
    "    window_name = 'Image'\n",
    "    # Start coordinate, here (5, 5) \n",
    "    # represents the top left corner of rectangle \n",
    "    start_point_p1 = (0, 0) \n",
    "    start_point_p2 = (render.shape[1]//2, 0)\n",
    "    \n",
    "    # Ending coordinate, here (220, 220) \n",
    "    # represents the bottom right corner of rectangle \n",
    "    end_point_p1 = (render.shape[1]//2, render.shape[0]) \n",
    "    end_point_p2 = (render.shape[1], render.shape[0])\n",
    "    \n",
    "    # Blue color in BGR \n",
    "    color = (255, 0, 0) \n",
    "    \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    \n",
    "    # ==========================================================================\n",
    "    \n",
    "    # getting the gesture showed by player 1\n",
    "    var_p1 = render[start_point_p1[1]:end_point_p1[1],start_point_p1[0]:end_point_p1[0],:]\n",
    "    \n",
    "    # converting the image from BGR to RGB\n",
    "    var_p1 = cv2.cvtColor(var_p1, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # converting image to array\n",
    "    var_p1 = array_to_img(var_p1)\n",
    "    \n",
    "    # resizing the image\n",
    "    var_p1 = var_p1.resize((96,96))\n",
    "    var_p1 = np.array(img_to_array(var_p1))\n",
    "    \n",
    "    # normalizing the image \n",
    "    var_p1 = var_p1/255\n",
    "    \n",
    "    # to avoid change in rows and columns series we used a list to increase one dimension \n",
    "    test1 = []\n",
    "    test1.append(var_p1)\n",
    "    x_p1 = np.array(test1)\n",
    "    \n",
    "    # predicting the output \n",
    "    pred_p1  = model.predict(x_p1)\n",
    "    class_p1.append(pred_p1)\n",
    "     \n",
    "    \n",
    "    # Using cv2.rectangle() method \n",
    "    # Draw a rectangle with blue line borders of thickness of 2 px \n",
    "    image = cv2.rectangle(render, (0,0), (render.shape[1]//2 , render.shape[1]), color, thickness)\n",
    "    \n",
    "    # text to be displayed according to the class value\n",
    "    if np.argmax(pred_p1)==0:\n",
    "        text_p1 =\"paper\"\n",
    "    if np.argmax(pred_p1)==1:\n",
    "        text_p1 =\"stone\"\n",
    "    if np.argmax(pred_p1)==2:\n",
    "        text_p1 =\"sc\"\n",
    "        \n",
    "    # putting the text to display the player 1    \n",
    "    cv2.putText(img = render, \n",
    "                text = \"p1 : \" + text_p1, \n",
    "                org = (int(200/2 - 20),int(200/2)), \n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale = 2, \n",
    "                thickness = 2,\n",
    "                color = (0, 100, 255))\n",
    "\n",
    "    #=====================================================================================\n",
    "\n",
    "    # The same process will happen with the player p2\n",
    "    \n",
    "    var_p2 = render[start_point_p2[1]:end_point_p2[1],start_point_p2[0]:end_point_p2[0],:]\n",
    "    \n",
    "    var_p2 = cv2.cvtColor(var_p2, cv2.COLOR_BGR2RGB)\n",
    "    var_p2 = array_to_img(var_p2)\n",
    "    \n",
    "    var_p2 = var_p2.resize((96,96))\n",
    "    var_p2 = np.array(img_to_array(var_p2))\n",
    "    \n",
    "    \n",
    "    var_p2 = var_p2/255\n",
    "    test2 = []\n",
    "    test2.append(var_p2)\n",
    "    x_p2 = np.array(test2)\n",
    "    \n",
    "    \n",
    "    pred_p2  = model.predict(x_p2)\n",
    "    class_p2.append(pred_p2) \n",
    "    \n",
    "    \n",
    "    if np.argmax(pred_p2)==0:\n",
    "        text_p2 =\"paper\"\n",
    "    if np.argmax(pred_p2)==1:\n",
    "        text_p2 =\"stone\"\n",
    "    if np.argmax(pred_p2)==2:\n",
    "        text_p2 =\"sc\"\n",
    "        \n",
    "    # putting text to display the player p2\n",
    "    cv2.putText(img = render, \n",
    "                text = \"p2 : \" + text_p2, \n",
    "                org = (int(1200/2 - 20),int(200/2)), \n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale = 2,                 \n",
    "                thickness = 2, \n",
    "                color = (189, 255, 0))\n",
    "    # displaying the video frame with detected faces\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "    if i%10 ==0:\n",
    "        txt,score_p1,score_p2 = decoding_gestures(class_p1,class_p2,score_p1,score_p2)\n",
    "        print(txt)\n",
    "        \n",
    "        # putting text to display the declear the winning player\n",
    "        cv2.putText(img = render, \n",
    "                    text = txt, \n",
    "                    org = (int(600/2 - 20),int(1200/2)), \n",
    "                    fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    fontScale = 2, \n",
    "                    thickness = 2,\n",
    "                    color = (0, 0, 255))\n",
    "        class_p1 = []\n",
    "        class_p2 = []\n",
    "    \n",
    "    # text to display the score of player 1\n",
    "    cv2.putText(img = render, \n",
    "                text = \"score : \" + str(score_p1), \n",
    "                org = (int(200/2 - 20),int(300/2)), \n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale = 1, \n",
    "                color = (0, 100, 255))\n",
    "    \n",
    "    # text to display the score of player 2\n",
    "    cv2.putText(img = render, \n",
    "                text = \"score : \" + str(score_p2), \n",
    "                org = (int(1200/2 - 20),int(300/2)), \n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale = 1, \n",
    "                color = (189, 255, 0))    \n",
    "    \n",
    "    cv2.imshow(window_name, render) \n",
    "    #cv2.imshow('frame',render)\n",
    "    \n",
    "    # setting our terminating commands\n",
    "    \n",
    "    if (cv2.waitKey(1)==ord('q')):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "\n",
    "    if(i==1000):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_p1,score_p2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
